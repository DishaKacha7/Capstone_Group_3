# -*- coding: utf-8 -*-
"""Evaluation score - Cross Entropy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1re2gcYxhOpCkbGy7cZdqhm0xSPzcvTqZ
"""

import numpy as np
import sklearn.metrics as metrics

class AccuracyMetrics:
    @staticmethod
    def cohen_kappa(y_true, y_pred):
        """
        Compute Cohen's Kappa score.
        """
        return metrics.cohen_kappa_score(y_true, y_pred)

    @staticmethod
    def cross_entropy_binary(y_true, y_pred_proba):
        """
        Compute cross-entropy loss for a binary outcome per crop (field level).
        Assumes y_pred_proba contains predicted probabilities for the positive class.
        """
        y_true = np.array(y_true)  # Convert to NumPy array
        epsilon = 1e-15  # Small value to avoid log(0)
        y_pred_proba = np.clip(y_pred_proba, epsilon, 1 - epsilon)
        return -np.mean(y_true * np.log(y_pred_proba) + (1 - y_true) * np.log(1 - y_pred_proba))

if __name__ == "__main__":
    # Sample test data
    y_true = [0, 1, 0, 1, 1]
    y_pred = [0, 1, 0, 0, 1]
    y_pred_proba = np.array([0.1, 0.9, 0.8, 0.2, 0.7])  # Ensure this is a NumPy array

    # Compute and print test results
    kappa_score = AccuracyMetrics.cohen_kappa(y_true, y_pred)
    cross_entropy = AccuracyMetrics.cross_entropy_binary(y_true, y_pred_proba)

    print(f"Cohen's Kappa Score: {kappa_score}")
    print(f"Cross Entropy Loss: {cross_entropy}")

